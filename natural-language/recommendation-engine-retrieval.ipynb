{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System: Retrieval Stage\n",
    "\n",
    "Retrieval models are often composed of two sub-models:\n",
    "\n",
    "- A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
    "- A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n",
    "\n",
    "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movielens', 'datasets', 'tiny_shakespeare', 'imdb_reviews', 'downloads']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"/database/tensorflow-datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 21:55:18.047556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.052587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.053178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.054093: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-16 21:55:18.057104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.058048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.058702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.481049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.481495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.481889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 21:55:18.482273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9163 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:2d:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\", data_dir=\"/database/tensorflow-datasets/\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\", data_dir=\"/database/tensorflow-datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 21:55:18.794950: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "\tpprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of key features here:\n",
    "\n",
    "- Movie title is useful as a movie identifier\n",
    "- Movie genre\n",
    "- User id is useful as a user identifier\n",
    "- User occupation label\n",
    "- User gender\n",
    "- Timestamps will allow us to model the effect of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4]),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 21:55:18.901218: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in movies.take(1).as_numpy_iterator():\n",
    "\tpprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of features\n",
    "ratings = ratings.map(lambda x: {\n",
    "\t\"movie_title\": x[\"movie_title\"],\n",
    "\t\"user_id\": x[\"user_id\"],\n",
    "\t\"user_occupation_text\": x[\"user_occupation_text\"],\n",
    "\t\"timestamp\": x[\"timestamp\"]\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test set (ideally based on time) using random split\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': b'Postman, The (1997)',\n",
      " 'timestamp': 885409515,\n",
      " 'user_id': b'681',\n",
      " 'user_occupation_text': b'marketing'}\n"
     ]
    }
   ],
   "source": [
    "for x in train.take(1).as_numpy_iterator():\n",
    "\tpprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': b'M*A*S*H (1970)',\n",
      " 'timestamp': 874948475,\n",
      " 'user_id': b'346',\n",
      " 'user_occupation_text': b'other'}\n"
     ]
    }
   ],
   "source": [
    "for x in test.take(1).as_numpy_iterator():\n",
    "\tpprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'1' b'10' b'100' b'101' b'102']\n",
      "[b\"'Til There Was You (1997)\" b'1-900 (1994)' b'101 Dalmatians (1996)'\n",
      " b'12 Angry Men (1957)' b'187 (1997)']\n",
      "[b'administrator' b'artist' b'doctor' b'educator' b'engineer']\n"
     ]
    }
   ],
   "source": [
    "# Get unique movies and user_id present in the data\n",
    "# movie_titles = movies.batch(1000).map(lambda x: x[\"movie_title\"])\n",
    "# user_occupation_text = ratings.batch(1000).map(lambda x: x[\"user_occupation_text\"])\n",
    "# user_ids = ratings.batch(1_000_00).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
    "unique_user_occupation_text = np.unique(np.hstack(list(ratings.batch(1_000).map(lambda x: x[\"user_occupation_text\"]))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(lambda x: x[\"user_id\"]))))\n",
    "\n",
    "print(unique_user_ids[:5])\n",
    "print(unique_movie_titles[:5])\n",
    "print(unique_user_occupation_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement model\n",
    "\n",
    "Choosing the architecture of our model is a key part of modelling.\n",
    "\n",
    "Because we are building a two-tower retrieval model, we can build each tower separately and then combine them in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets: [8.74724710e+08 8.74743291e+08 8.74761871e+08]\n"
     ]
    }
   ],
   "source": [
    "# Create timestamp buckets as timestamps in general are too large to be used with any deep learning model\n",
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "max_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(tf.cast(0, tf.int64), tf.maximum).numpy().max()\n",
    "min_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(np.int64(1e9), tf.minimum).numpy().min()\n",
    "\n",
    "timestamp_buckets = np.linspace(min_timestamp, max_timestamp, num=1000)\n",
    "\n",
    "print(f\"Buckets: {timestamp_buckets[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\tdef __init__(self) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.user_embedding = tf.keras.Sequential(\n",
    "\t\t\t[\n",
    "\t\t\t\ttf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "\t\t\t\ttf.keras.layers.Embedding(len(unique_user_ids)+1, 64)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t\tself.occupation_text_embedding = tf.keras.Sequential(\n",
    "\t\t\t[\n",
    "\t\t\t\ttf.keras.layers.StringLookup(vocabulary=unique_user_occupation_text, mask_token=None),\n",
    "\t\t\t\ttf.keras.layers.Embedding(len(unique_user_occupation_text)+1, 31)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t\tself.timestamp_embedding = tf.keras.Sequential(\n",
    "\t\t\t[\n",
    "\t\t\t\ttf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "\t\t\t\ttf.keras.layers.Embedding(len(timestamp_buckets) + 2, 32)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t\tself.timestamp_normalization = tf.keras.layers.Normalization(axis=None)\n",
    "\t\tself.timestamp_normalization.adapt(timestamps)\n",
    "\t\n",
    "\tdef call(self, inputs):\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.user_embedding(inputs[\"user_id\"]),\n",
    "\t\t\tself.occupation_text_embedding(inputs[\"user_occupation_text\"]),\n",
    "\t\t\tself.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "\t\t\ttf.reshape(self.timestamp_normalization(inputs[\"timestamp\"]), (-1, 1))\n",
    "\t\t\t], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try it out\n",
    "user_model = UserModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\tdef __init__(self) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.title_embedding = tf.keras.Sequential(\n",
    "\t\t\t[\n",
    "\t\t\t\ttf.keras.layers.StringLookup(vocabulary=unique_movie_titles, mask_token=None),\n",
    "\t\t\t\ttf.keras.layers.Embedding(len(unique_movie_titles)+1, 64)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t\tself.title_vectorizer = tf.keras.layers.TextVectorization(max_tokens=10000)\n",
    "\t\tself.title_text_embedding = tf.keras.Sequential(\n",
    "\t\t\t[\n",
    "\t\t\t\tself.title_vectorizer,\n",
    "\t\t\t\ttf.keras.layers.Embedding(10000, 64, mask_zero=True),\n",
    "\t\t\t\ttf.keras.layers.GlobalAveragePooling1D()\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t\tself.title_vectorizer.adapt(movies)\n",
    "\t\n",
    "\tdef call(self, movie_title):\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.title_embedding(movie_title),\n",
    "\t\t\tself.title_text_embedding(movie_title)\n",
    "\t\t\t], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try it out\n",
    "movie_model = MovieModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our training data we have positive (user, movie) pairs. \n",
    "\n",
    "To figure out how good our model is, we need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates: if the score for the positive pair is higher than for all other candidates, our model is highly accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set metric\n",
    "metrics = tfrs.metrics.FactorizedTopK(candidates=movies.batch(128).map(movie_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set objective\n",
    "retrieval_task = tfrs.tasks.Retrieval(metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task itself is a keras layer that takes the query and candidate embeddings as arguments, and returns the computed loss: we'll use that to implement the model's training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the candidate and user model to build the complete retrieval model\n",
    "class MovielensModel(tfrs.Model):\n",
    "\tdef __init__(self, user_model, movie_model, retrieval_task):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.movie_model = movie_model\n",
    "\t\tself.user_model = user_model\n",
    "\t\tself.task = retrieval_task\n",
    "\t\n",
    "\tdef compute_loss(self, features, training=False):\n",
    "\t\tembedding_1 = self.user_model({\n",
    "\t\t\t\"user_id\": features[\"user_id\"],\n",
    "\t\t\t\"user_occupation_text\": features[\"user_occupation_text\"],\n",
    "\t\t\t\"timestamp\": features[\"timestamp\"]\n",
    "\t\t})\n",
    "\t\tembedding_2 = self.movie_model(features[\"movie_title\"])\n",
    "\t\treturn self.task(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tfrs.Model base class is a simply convenience class: it allows us to compute both training and test losses using the same method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get combined model\n",
    "main_model = MovielensModel(user_model, movie_model, retrieval_task)\n",
    "\n",
    "# Compile model\n",
    "main_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now shuffle, batch and cache training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(4096).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 7s 258ms/step - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0043 - factorized_top_k/top_10_categorical_accuracy: 0.0091 - factorized_top_k/top_50_categorical_accuracy: 0.0448 - factorized_top_k/top_100_categorical_accuracy: 0.0840 - loss: 32402.9842 - regularization_loss: 0.0000e+00 - total_loss: 32402.9842 - val_factorized_top_k/top_1_categorical_accuracy: 0.0014 - val_factorized_top_k/top_5_categorical_accuracy: 0.0080 - val_factorized_top_k/top_10_categorical_accuracy: 0.0153 - val_factorized_top_k/top_50_categorical_accuracy: 0.0625 - val_factorized_top_k/top_100_categorical_accuracy: 0.1102 - val_loss: 29596.5801 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29596.5801\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 4s 195ms/step - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0093 - factorized_top_k/top_10_categorical_accuracy: 0.0187 - factorized_top_k/top_50_categorical_accuracy: 0.0760 - factorized_top_k/top_100_categorical_accuracy: 0.1368 - loss: 32334.0941 - regularization_loss: 0.0000e+00 - total_loss: 32334.0941 - val_factorized_top_k/top_1_categorical_accuracy: 0.0016 - val_factorized_top_k/top_5_categorical_accuracy: 0.0107 - val_factorized_top_k/top_10_categorical_accuracy: 0.0205 - val_factorized_top_k/top_50_categorical_accuracy: 0.0747 - val_factorized_top_k/top_100_categorical_accuracy: 0.1338 - val_loss: 29527.6465 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29527.6465\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 4s 193ms/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0143 - factorized_top_k/top_10_categorical_accuracy: 0.0276 - factorized_top_k/top_50_categorical_accuracy: 0.1011 - factorized_top_k/top_100_categorical_accuracy: 0.1752 - loss: 32215.9174 - regularization_loss: 0.0000e+00 - total_loss: 32215.9174 - val_factorized_top_k/top_1_categorical_accuracy: 0.0018 - val_factorized_top_k/top_5_categorical_accuracy: 0.0131 - val_factorized_top_k/top_10_categorical_accuracy: 0.0261 - val_factorized_top_k/top_50_categorical_accuracy: 0.0922 - val_factorized_top_k/top_100_categorical_accuracy: 0.1609 - val_loss: 29419.3340 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29419.3340\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 4s 194ms/step - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0177 - factorized_top_k/top_10_categorical_accuracy: 0.0344 - factorized_top_k/top_50_categorical_accuracy: 0.1270 - factorized_top_k/top_100_categorical_accuracy: 0.2119 - loss: 32057.8962 - regularization_loss: 0.0000e+00 - total_loss: 32057.8962 - val_factorized_top_k/top_1_categorical_accuracy: 0.0023 - val_factorized_top_k/top_5_categorical_accuracy: 0.0151 - val_factorized_top_k/top_10_categorical_accuracy: 0.0286 - val_factorized_top_k/top_50_categorical_accuracy: 0.1112 - val_factorized_top_k/top_100_categorical_accuracy: 0.1896 - val_loss: 29288.6133 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29288.6133\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 4s 193ms/step - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0191 - factorized_top_k/top_10_categorical_accuracy: 0.0378 - factorized_top_k/top_50_categorical_accuracy: 0.1478 - factorized_top_k/top_100_categorical_accuracy: 0.2439 - loss: 31880.5024 - regularization_loss: 0.0000e+00 - total_loss: 31880.5024 - val_factorized_top_k/top_1_categorical_accuracy: 0.0023 - val_factorized_top_k/top_5_categorical_accuracy: 0.0152 - val_factorized_top_k/top_10_categorical_accuracy: 0.0287 - val_factorized_top_k/top_50_categorical_accuracy: 0.1229 - val_factorized_top_k/top_100_categorical_accuracy: 0.2110 - val_loss: 29154.3945 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29154.3945\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 4s 192ms/step - factorized_top_k/top_1_categorical_accuracy: 3.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0200 - factorized_top_k/top_10_categorical_accuracy: 0.0411 - factorized_top_k/top_50_categorical_accuracy: 0.1615 - factorized_top_k/top_100_categorical_accuracy: 0.2668 - loss: 31703.4263 - regularization_loss: 0.0000e+00 - total_loss: 31703.4263 - val_factorized_top_k/top_1_categorical_accuracy: 0.0023 - val_factorized_top_k/top_5_categorical_accuracy: 0.0148 - val_factorized_top_k/top_10_categorical_accuracy: 0.0286 - val_factorized_top_k/top_50_categorical_accuracy: 0.1312 - val_factorized_top_k/top_100_categorical_accuracy: 0.2262 - val_loss: 29030.0781 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29030.0781\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 4s 192ms/step - factorized_top_k/top_1_categorical_accuracy: 3.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0209 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.1720 - factorized_top_k/top_100_categorical_accuracy: 0.2835 - loss: 31538.1283 - regularization_loss: 0.0000e+00 - total_loss: 31538.1283 - val_factorized_top_k/top_1_categorical_accuracy: 0.0019 - val_factorized_top_k/top_5_categorical_accuracy: 0.0135 - val_factorized_top_k/top_10_categorical_accuracy: 0.0285 - val_factorized_top_k/top_50_categorical_accuracy: 0.1355 - val_factorized_top_k/top_100_categorical_accuracy: 0.2368 - val_loss: 28920.5508 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28920.5508\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 4s 192ms/step - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0219 - factorized_top_k/top_10_categorical_accuracy: 0.0450 - factorized_top_k/top_50_categorical_accuracy: 0.1806 - factorized_top_k/top_100_categorical_accuracy: 0.2964 - loss: 31388.1942 - regularization_loss: 0.0000e+00 - total_loss: 31388.1942 - val_factorized_top_k/top_1_categorical_accuracy: 0.0016 - val_factorized_top_k/top_5_categorical_accuracy: 0.0138 - val_factorized_top_k/top_10_categorical_accuracy: 0.0284 - val_factorized_top_k/top_50_categorical_accuracy: 0.1391 - val_factorized_top_k/top_100_categorical_accuracy: 0.2428 - val_loss: 28825.8594 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28825.8594\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 4s 193ms/step - factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0224 - factorized_top_k/top_10_categorical_accuracy: 0.0466 - factorized_top_k/top_50_categorical_accuracy: 0.1884 - factorized_top_k/top_100_categorical_accuracy: 0.3071 - loss: 31253.4407 - regularization_loss: 0.0000e+00 - total_loss: 31253.4407 - val_factorized_top_k/top_1_categorical_accuracy: 0.0021 - val_factorized_top_k/top_5_categorical_accuracy: 0.0128 - val_factorized_top_k/top_10_categorical_accuracy: 0.0288 - val_factorized_top_k/top_50_categorical_accuracy: 0.1408 - val_factorized_top_k/top_100_categorical_accuracy: 0.2459 - val_loss: 28744.4492 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28744.4492\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 4s 192ms/step - factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0232 - factorized_top_k/top_10_categorical_accuracy: 0.0478 - factorized_top_k/top_50_categorical_accuracy: 0.1949 - factorized_top_k/top_100_categorical_accuracy: 0.3160 - loss: 31132.4993 - regularization_loss: 0.0000e+00 - total_loss: 31132.4993 - val_factorized_top_k/top_1_categorical_accuracy: 0.0014 - val_factorized_top_k/top_5_categorical_accuracy: 0.0132 - val_factorized_top_k/top_10_categorical_accuracy: 0.0289 - val_factorized_top_k/top_50_categorical_accuracy: 0.1423 - val_factorized_top_k/top_100_categorical_accuracy: 0.2483 - val_loss: 28674.5195 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28674.5195\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 4s 193ms/step - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0236 - factorized_top_k/top_10_categorical_accuracy: 0.0489 - factorized_top_k/top_50_categorical_accuracy: 0.1998 - factorized_top_k/top_100_categorical_accuracy: 0.3235 - loss: 31023.7582 - regularization_loss: 0.0000e+00 - total_loss: 31023.7582 - val_factorized_top_k/top_1_categorical_accuracy: 0.0014 - val_factorized_top_k/top_5_categorical_accuracy: 0.0127 - val_factorized_top_k/top_10_categorical_accuracy: 0.0300 - val_factorized_top_k/top_50_categorical_accuracy: 0.1431 - val_factorized_top_k/top_100_categorical_accuracy: 0.2526 - val_loss: 28614.3691 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28614.3691\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 4s 191ms/step - factorized_top_k/top_1_categorical_accuracy: 3.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0243 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2038 - factorized_top_k/top_100_categorical_accuracy: 0.3295 - loss: 30925.6416 - regularization_loss: 0.0000e+00 - total_loss: 30925.6416 - val_factorized_top_k/top_1_categorical_accuracy: 0.0016 - val_factorized_top_k/top_5_categorical_accuracy: 0.0125 - val_factorized_top_k/top_10_categorical_accuracy: 0.0296 - val_factorized_top_k/top_50_categorical_accuracy: 0.1434 - val_factorized_top_k/top_100_categorical_accuracy: 0.2533 - val_loss: 28562.4805 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28562.4805\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 4s 193ms/step - factorized_top_k/top_1_categorical_accuracy: 4.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0513 - factorized_top_k/top_50_categorical_accuracy: 0.2082 - factorized_top_k/top_100_categorical_accuracy: 0.3348 - loss: 30836.6991 - regularization_loss: 0.0000e+00 - total_loss: 30836.6991 - val_factorized_top_k/top_1_categorical_accuracy: 0.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0125 - val_factorized_top_k/top_10_categorical_accuracy: 0.0288 - val_factorized_top_k/top_50_categorical_accuracy: 0.1445 - val_factorized_top_k/top_100_categorical_accuracy: 0.2549 - val_loss: 28517.5430 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28517.5430\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 4s 192ms/step - factorized_top_k/top_1_categorical_accuracy: 3.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0253 - factorized_top_k/top_10_categorical_accuracy: 0.0522 - factorized_top_k/top_50_categorical_accuracy: 0.2118 - factorized_top_k/top_100_categorical_accuracy: 0.3399 - loss: 30755.6422 - regularization_loss: 0.0000e+00 - total_loss: 30755.6422 - val_factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0126 - val_factorized_top_k/top_10_categorical_accuracy: 0.0284 - val_factorized_top_k/top_50_categorical_accuracy: 0.1449 - val_factorized_top_k/top_100_categorical_accuracy: 0.2569 - val_loss: 28478.4434 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28478.4434\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 4s 193ms/step - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0259 - factorized_top_k/top_10_categorical_accuracy: 0.0533 - factorized_top_k/top_50_categorical_accuracy: 0.2136 - factorized_top_k/top_100_categorical_accuracy: 0.3438 - loss: 30681.3541 - regularization_loss: 0.0000e+00 - total_loss: 30681.3541 - val_factorized_top_k/top_1_categorical_accuracy: 0.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0127 - val_factorized_top_k/top_10_categorical_accuracy: 0.0281 - val_factorized_top_k/top_50_categorical_accuracy: 0.1452 - val_factorized_top_k/top_100_categorical_accuracy: 0.2568 - val_loss: 28444.2500 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28444.2500\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 4s 195ms/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0266 - factorized_top_k/top_10_categorical_accuracy: 0.0541 - factorized_top_k/top_50_categorical_accuracy: 0.2160 - factorized_top_k/top_100_categorical_accuracy: 0.3473 - loss: 30612.8848 - regularization_loss: 0.0000e+00 - total_loss: 30612.8848 - val_factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0122 - val_factorized_top_k/top_10_categorical_accuracy: 0.0283 - val_factorized_top_k/top_50_categorical_accuracy: 0.1448 - val_factorized_top_k/top_100_categorical_accuracy: 0.2582 - val_loss: 28414.1992 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28414.1992\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 4s 193ms/step - factorized_top_k/top_1_categorical_accuracy: 5.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0268 - factorized_top_k/top_10_categorical_accuracy: 0.0553 - factorized_top_k/top_50_categorical_accuracy: 0.2184 - factorized_top_k/top_100_categorical_accuracy: 0.3508 - loss: 30549.4351 - regularization_loss: 0.0000e+00 - total_loss: 30549.4351 - val_factorized_top_k/top_1_categorical_accuracy: 8.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0124 - val_factorized_top_k/top_10_categorical_accuracy: 0.0276 - val_factorized_top_k/top_50_categorical_accuracy: 0.1444 - val_factorized_top_k/top_100_categorical_accuracy: 0.2575 - val_loss: 28387.6523 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28387.6523\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 4s 194ms/step - factorized_top_k/top_1_categorical_accuracy: 5.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0274 - factorized_top_k/top_10_categorical_accuracy: 0.0563 - factorized_top_k/top_50_categorical_accuracy: 0.2207 - factorized_top_k/top_100_categorical_accuracy: 0.3536 - loss: 30490.3338 - regularization_loss: 0.0000e+00 - total_loss: 30490.3338 - val_factorized_top_k/top_1_categorical_accuracy: 9.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0123 - val_factorized_top_k/top_10_categorical_accuracy: 0.0274 - val_factorized_top_k/top_50_categorical_accuracy: 0.1434 - val_factorized_top_k/top_100_categorical_accuracy: 0.2579 - val_loss: 28364.1016 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28364.1016\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 4s 195ms/step - factorized_top_k/top_1_categorical_accuracy: 6.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0277 - factorized_top_k/top_10_categorical_accuracy: 0.0570 - factorized_top_k/top_50_categorical_accuracy: 0.2226 - factorized_top_k/top_100_categorical_accuracy: 0.3560 - loss: 30435.0211 - regularization_loss: 0.0000e+00 - total_loss: 30435.0211 - val_factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0121 - val_factorized_top_k/top_10_categorical_accuracy: 0.0268 - val_factorized_top_k/top_50_categorical_accuracy: 0.1430 - val_factorized_top_k/top_100_categorical_accuracy: 0.2578 - val_loss: 28343.1250 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28343.1250\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 4s 192ms/step - factorized_top_k/top_1_categorical_accuracy: 6.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0280 - factorized_top_k/top_10_categorical_accuracy: 0.0580 - factorized_top_k/top_50_categorical_accuracy: 0.2247 - factorized_top_k/top_100_categorical_accuracy: 0.3588 - loss: 30383.0279 - regularization_loss: 0.0000e+00 - total_loss: 30383.0279 - val_factorized_top_k/top_1_categorical_accuracy: 0.0011 - val_factorized_top_k/top_5_categorical_accuracy: 0.0120 - val_factorized_top_k/top_10_categorical_accuracy: 0.0268 - val_factorized_top_k/top_50_categorical_accuracy: 0.1418 - val_factorized_top_k/top_100_categorical_accuracy: 0.2582 - val_loss: 28324.3711 - val_regularization_loss: 0.0000e+00 - val_total_loss: 28324.3711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7014686040>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "main_model.fit(\n",
    "\tcached_train, epochs=20, validation_data=cached_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 160ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0120 - factorized_top_k/top_10_categorical_accuracy: 0.0268 - factorized_top_k/top_50_categorical_accuracy: 0.1418 - factorized_top_k/top_100_categorical_accuracy: 0.2582 - loss: 31152.1572 - regularization_loss: 0.0000e+00 - total_loss: 31152.1572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0010999999940395355,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.011950000189244747,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.026750000193715096,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.14184999465942383,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.25824999809265137,\n",
       " 'loss': 28324.37109375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28324.37109375}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "main_model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we created a user-movie model. However, for some applications (for example, product detail pages) it's common to perform item-to-item (for example, movie-to-movie or product-to-product) recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
